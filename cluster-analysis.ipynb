{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " by Thibaut Perol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>origintime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>err_lon</th>\n",
       "      <th>err_lat</th>\n",
       "      <th>err_depth</th>\n",
       "      <th>err_origintime</th>\n",
       "      <th>county</th>\n",
       "      <th>origin_src</th>\n",
       "      <th>prefmag</th>\n",
       "      <th>pmag_type</th>\n",
       "      <th>pmag_src</th>\n",
       "      <th>mw</th>\n",
       "      <th>mw_src</th>\n",
       "      <th>mblg_ogs</th>\n",
       "      <th>mblg_usgs</th>\n",
       "      <th>ml_ogs</th>\n",
       "      <th>m3hz_ogs</th>\n",
       "      <th>md_ogs</th>\n",
       "      <th>mb</th>\n",
       "      <th>ms</th>\n",
       "      <th>mfa</th>\n",
       "      <th>max_mmi</th>\n",
       "      <th>reafile</th>\n",
       "      <th>reamtime</th>\n",
       "      <th>geom</th>\n",
       "      <th>pdlid</th>\n",
       "      <th>mw_ogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>1980-01-05 07:11:31.21</td>\n",
       "      <td>35.586</td>\n",
       "      <td>-97.894</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANADIAN</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.9</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E6100000F0A7C64B377958C05EBA490C02CB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>1980-01-12 07:12:56.45</td>\n",
       "      <td>36.453</td>\n",
       "      <td>-97.642</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GARFIELD</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.7</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000000C022B87166958C0448B6CE7FB39...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>1980-02-03 00:46:30.05</td>\n",
       "      <td>33.994</td>\n",
       "      <td>-97.463</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>1980-02-05 04:32:35.45</td>\n",
       "      <td>34.046</td>\n",
       "      <td>-97.451</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.1</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>1980-03-09 03:57:10.56</td>\n",
       "      <td>35.100</td>\n",
       "      <td>-95.100</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HASKELL</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000006666666666C657C0CDCCCCCCCC8C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id              origintime  latitude  longitude  depth  err_lon  err_lat  err_depth  err_origintime    county origin_src  prefmag pmag_type pmag_src  mw mw_src  mblg_ogs  mblg_usgs  ml_ogs  m3hz_ogs  md_ogs  mb  ms  mfa  max_mmi reafile reamtime                                               geom  pdlid  mw_ogs\n",
       "0  255  1980-01-05 07:11:31.21    35.586    -97.894      5      NaN      NaN        NaN             NaN  CANADIAN        OGS      1.9      M3Hz      OGS NaN    NaN       1.6        NaN     NaN       1.9     1.7 NaN NaN  NaN      NaN     NaN      NaN  0101000020E6100000F0A7C64B377958C05EBA490C02CB...    NaN     NaN\n",
       "1  256  1980-01-12 07:12:56.45    36.453    -97.642      5      NaN      NaN        NaN             NaN  GARFIELD        OGS      1.7      M3Hz      OGS NaN    NaN       NaN        NaN     NaN       1.7     1.4 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000000C022B87166958C0448B6CE7FB39...    NaN     NaN\n",
       "2  257  1980-02-03 00:46:30.05    33.994    -97.463      5      NaN      NaN        NaN             NaN      LOVE        OGS      2.2      M3Hz      OGS NaN    NaN       1.9        NaN     NaN       2.2     2.0 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...    NaN     NaN\n",
       "3  258  1980-02-05 04:32:35.45    34.046    -97.451      5      NaN      NaN        NaN             NaN      LOVE        OGS      2.1      M3Hz      OGS NaN    NaN       2.3        NaN     NaN       2.1     1.9 NaN NaN  NaN        3     NaN      NaN  0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...    NaN     NaN\n",
       "4  259  1980-03-09 03:57:10.56    35.100    -95.100      5      NaN      NaN        NaN             NaN   HASKELL        OGS      1.2      M3Hz      OGS NaN    NaN       1.4        NaN     NaN       1.2     1.4 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000006666666666C657C0CDCCCCCCCC8C...    NaN     NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the dataframe with 1980 data\n",
    "since_1980_df = pd.DataFrame()\n",
    "since_1980_df = pd.read_csv('http://wichita.ogs.ou.edu/eq/catalog/1980/1980.csv')\n",
    "\n",
    "# add additional years\n",
    "for year in range(1981,2016):\n",
    "    url = 'http://wichita.ogs.ou.edu/eq/catalog/' + str(year) + '/' + str(year) + '.csv'\n",
    "    temp_df = pd.read_csv(url)\n",
    "    # This might not be the most efficient method\n",
    "    since_1980_df = since_1980_df.append(temp_df)\n",
    "since_1980_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract year of earthquake events\n",
    "import time\n",
    "year_day = []\n",
    "year = []\n",
    "for date in since_1980_df.origintime.values:\n",
    "    new_date = time.strptime(date[:19], \"%Y-%m-%d %H:%M:%S\")\n",
    "    year_day.append(new_date.tm_yday)\n",
    "    year.append(new_date.tm_year)\n",
    "# Add to data frame the day of a year of earthquake\n",
    "since_1980_df['year_day'] = year_day\n",
    "# Add to data frame the year of earthquake\n",
    "since_1980_df['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18895, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since_1980_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am testing the DBSCAN clustering algorithm with a subset of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define subset of data\n",
    "# choose randomly 1e3 values\n",
    "sample_size = 1000\n",
    "subset = since_1980_df.iloc[random.sample(since_1980_df.index,sample_size)]\n",
    "# import libraries for DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##############################################################################\n",
    "# Compute DBSCAN\n",
    "X = [subset.latitude,subset.longitude]\n",
    "db = DBSCAN().fit(X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
